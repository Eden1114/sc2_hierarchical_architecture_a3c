0219:这一次的参数有可能造兵，改进了reward之后可能有助于agent的选点和学习；需要测试agent的结束机制：如果胜利了，没有点击接受对面的gg，而是等到超时自动结束该轮游戏，那么是算胜利还是失败？；
改写main的命令行参数，max_agent_steps设置为4000-5000，与reward匹配；会出现“突然失忆”，类似于参数发散，大约在50回合左右就开始了。由于随机性的影响，跳出了收敛向局部最优解的方向，走向发散。

0220：改写了max_agent_steps为5000；人工操作造枪兵之后，电脑好像学到了一点造枪兵的方法；不分胜负的强制结束，系统reward是0；不接受gg，reward也是0；只有强行打退，或者接受gg，reward才是1